{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from mnist import MNIST\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can create constants and variables of different types. \n",
    "#However, the different types do not mix well together.\n",
    "a = tf.constant(2, tf.int16)\n",
    "b = tf.constant(4, tf.float32)\n",
    "c = tf.constant(8, tf.float32)\n",
    "\n",
    "d = tf.Variable(2, tf.int16)\n",
    "e = tf.Variable(4, tf.float32)\n",
    "f = tf.Variable(8, tf.float32)\n",
    "\n",
    "#we can perform computations on variable of the same type: e + f\n",
    "#but the following can not be done: d + e\n",
    "\n",
    "#everything in tensorflow is a tensor, these can have different dimensions:\n",
    "#0D, 1D, 2D, 3D, 4D, or nD-tensors\n",
    "g = tf.constant(np.zeros(shape=(2,2), dtype=np.float32)) #does work\n",
    "\n",
    "h = tf.zeros([11], tf.int16)\n",
    "i = tf.ones([2,2], tf.float32)\n",
    "j = tf.zeros([1000,4,3], tf.float64)\n",
    "\n",
    "k = tf.Variable(tf.zeros([2,2], tf.float32))\n",
    "l = tf.Variable(tf.zeros([5,6,5], tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.truncated_normal([256 * 256, 10]))\n",
    "biases = tf.Variable(tf.zeros([10]))\n",
    "print(weights.get_shape().as_list())\n",
    "print(biases.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    a = tf.Variable(8, tf.float32, name=\"a\")\n",
    "    b = tf.Variable(tf.zeros([2,2], tf.float32))\n",
    "    \n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    writer = tf.summary.FileWriter('./graph1', session.graph)\n",
    "    writer.close()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(a)\n",
    "    print(session.run(a))\n",
    "    print(b)\n",
    "    print(session.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_points1_ = [[1,2], [3,4], [5,6], [7,8]]\n",
    "list_of_points2_ = [[15,16], [13,14], [11,12], [9,10]]\n",
    "list_of_points1 = np.array([np.array(elem).reshape(1,2) for elem in list_of_points1_])\n",
    "list_of_points2 = np.array([np.array(elem).reshape(1,2) for elem in list_of_points2_])\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    #we should use a tf.placeholder() to create a variable whose value you will fill in later (during session.run()). \n",
    "    #this can be done by 'feeding' the data into the placeholder.\n",
    "    #below we see an example of a method which uses two placeholder arrays of size [2,1] to calculate the eucledian distance\n",
    "\n",
    "    point1 = tf.placeholder(tf.float32, shape=(1, 2), name=\"p1\")\n",
    "    point2 = tf.placeholder(tf.float32, shape=(1, 2), name=\"p2\")\n",
    "    \n",
    "    def calculate_eucledian_distance(point1, point2):\n",
    "        difference = tf.subtract(point1, point2, \"dif1\")\n",
    "        power2 = tf.pow(difference, tf.constant(2.0, shape=(1,2), name=\"powr2\"), name=\"pow1\")\n",
    "        add = tf.reduce_sum(power2, name=\"add1\")\n",
    "        eucledian_distance = tf.sqrt(add, name=\"euc1\")\n",
    "        return eucledian_distance\n",
    "    \n",
    "    dist = calculate_eucledian_distance(point1, point2)\n",
    "    \n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    writer = tf.summary.FileWriter('./graph2', session.graph)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for ii in range(len(list_of_points1)):\n",
    "        point1_ = list_of_points1[ii]\n",
    "        point2_ = list_of_points2[ii]\n",
    "        feed_dict = {point1 : point1_, point2 : point2_}\n",
    "        distance = session.run([dist], feed_dict=feed_dict)\n",
    "        print(\"the distance between {} and {} -> {}\".format(point1_, point2_, distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_points1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session._closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.shape(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation, :, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "def one_hot_encode(np_array):\n",
    "    return (np.arange(10) == np_array[:,None]).astype(np.float32)\n",
    "\n",
    "def reformat_data(dataset, labels, image_width, image_height, image_depth):\n",
    "    np_dataset_ = np.array([np.array(image_data).reshape(image_width, image_height, image_depth) for image_data in dataset])\n",
    "    np_labels_ = one_hot_encode(np.array(labels, dtype=np.float32))\n",
    "    np_dataset, np_labels = randomize(np_dataset_, np_labels_)\n",
    "    return np_dataset, np_labels\n",
    "\n",
    "def flatten_tf_array(array):\n",
    "    shape = array.get_shape().as_list()\n",
    "    return tf.reshape(array, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60000, 28, 28, 1]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(train_dataset).get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.arange(10)\n",
    "\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_folder = './data/mnist/'\n",
    "mnist_image_width = 28\n",
    "mnist_image_height = 28\n",
    "mnist_image_depth = 1\n",
    "mnist_num_labels = 10\n",
    "\n",
    "mndata = MNIST(mnist_folder)\n",
    "\n",
    "mnist_train_dataset_, mnist_train_labels_ = mndata.load_training()\n",
    "mnist_test_dataset_, mnist_test_labels_ = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mnist_train_dataset_))\n",
    "print(len(mnist_train_dataset_[0]))  #28x28 image\n",
    "print(mnist_train_dataset_[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset, mnist_train_labels = reformat_data(mnist_train_dataset_, mnist_train_labels_, mnist_image_width, mnist_image_height, mnist_image_depth)\n",
    "mnist_test_dataset, mnist_test_labels = reformat_data(mnist_test_dataset_, mnist_test_labels_, mnist_image_width, mnist_image_height, mnist_image_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mnist_train_dataset))\n",
    "print(mnist_train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type( mnist_train_labels))\n",
    "print( mnist_train_labels.shape)\n",
    "\n",
    "print( mnist_train_labels[:10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mnist import MNIST\n",
    "\n",
    "mnist_folder = './data/mnist/'\n",
    "mnist_image_width = 28\n",
    "mnist_image_height = 28\n",
    "mnist_image_depth = 1\n",
    "mnist_num_labels = 10\n",
    "\n",
    "mndata = MNIST(mnist_folder)\n",
    "mnist_train_dataset_, mnist_train_labels_ = mndata.load_training()\n",
    "mnist_test_dataset_, mnist_test_labels_ = mndata.load_testing()\n",
    "\n",
    "mnist_train_dataset, mnist_train_labels = reformat_data(mnist_train_dataset_, mnist_train_labels_, mnist_image_width, mnist_image_height, mnist_image_depth)\n",
    "mnist_test_dataset, mnist_test_labels = reformat_data(mnist_test_dataset_, mnist_test_labels_, mnist_image_width, mnist_image_height, mnist_image_depth)\n",
    "\n",
    "print(\"There are {} images, each of size {}\".format(len(mnist_train_dataset), len(mnist_train_dataset[0])))\n",
    "print(\"Meaning each image has the size of 28*28*1 = {}\".format(mnist_image_width*mnist_image_height*1))\n",
    "print(\"The training set contains the following {} labels: {}\".format(len(np.unique(mnist_train_labels_)), np.unique(mnist_train_labels_)))\n",
    "\n",
    "print('Training set shape', mnist_train_dataset.shape, mnist_train_labels.shape)\n",
    "print('Test set shape', mnist_test_dataset.shape, mnist_test_labels.shape)\n",
    "\n",
    "train_dataset_mnist, train_labels_mnist = mnist_train_dataset, mnist_train_labels\n",
    "test_dataset_mnist, test_labels_mnist = mnist_test_dataset, mnist_test_labels\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "# cifar10_folder = './data/cifar10/'\n",
    "# train_datasets = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', ]\n",
    "# test_dataset = ['test_batch']\n",
    "# c10_image_height = 32\n",
    "# c10_image_width = 32\n",
    "# c10_image_depth = 3\n",
    "# c10_num_labels = 10\n",
    "\n",
    "# with open(cifar10_folder + test_dataset[0], 'rb') as f0:\n",
    "#     c10_test_dict = pickle.load(f0, encoding='bytes')\n",
    "\n",
    "# c10_test_dataset, c10_test_labels = c10_test_dict[b'data'], c10_test_dict[b'labels']\n",
    "# test_dataset_cifar10, test_labels_cifar10 = reformat_data(c10_test_dataset, c10_test_labels, c10_image_width, c10_image_height, c10_image_depth)\n",
    "\n",
    "# c10_train_dataset, c10_train_labels = [], []\n",
    "# for train_dataset in train_datasets:\n",
    "#     with open(cifar10_folder + train_dataset, 'rb') as f0:\n",
    "#         c10_train_dict = pickle.load(f0, encoding='bytes')\n",
    "#         c10_train_dataset_, c10_train_labels_ = c10_train_dict[b'data'], c10_train_dict[b'labels']\n",
    " \n",
    "#         c10_train_dataset.append(c10_train_dataset_)\n",
    "#         c10_train_labels += c10_train_labels_\n",
    "\n",
    "# c10_train_dataset = np.concatenate(c10_train_dataset, axis=0)\n",
    "# train_dataset_cifar10, train_labels_cifar10 = reformat_data(c10_train_dataset, c10_train_labels, c10_image_width, c10_image_height, c10_image_depth)\n",
    "# del c10_train_dataset\n",
    "# del c10_train_labels\n",
    "\n",
    "# print(\"The training set contains the following labels: {}\".format(np.unique(c10_train_dict[b'labels'])))\n",
    "# print('Training set shape', train_dataset_cifar10.shape, train_labels_cifar10.shape)\n",
    "# print('Test set shape', test_dataset_cifar10.shape, test_labels_cifar10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = mnist_image_width\n",
    "image_height = mnist_image_height\n",
    "image_depth = mnist_image_depth\n",
    "num_labels = mnist_num_labels \n",
    "\n",
    "#the dataset\n",
    "train_dataset = mnist_train_dataset\n",
    "train_labels = mnist_train_labels \n",
    "test_dataset = mnist_test_dataset\n",
    "test_labels = mnist_test_labels \n",
    "\n",
    "#number of iterations and learning rate\n",
    "num_steps = 10001\n",
    "display_step = 1000\n",
    "learning_rate = 0.5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = []\n",
    "for step in range(num_steps):\n",
    "    offset.append((step * batch_size) % (train_labels.shape[0] - batch_size))\n",
    "#     print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n"
     ]
    }
   ],
   "source": [
    "print(len(offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22ae7e579e8>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160\n",
      "32\n",
      "320000\n",
      "60000\n",
      "59968\n"
     ]
    }
   ],
   "source": [
    "offset = (10000 * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "\n",
    "print(offset)\n",
    "\n",
    "print(batch_size)\n",
    "\n",
    "print(10000 * batch_size)\n",
    "\n",
    "print(train_labels.shape[0])\n",
    "\n",
    "print(train_labels.shape[0] - batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 28, 28, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tf_test_dataset.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 10]\n"
     ]
    }
   ],
   "source": [
    "print(test_prediction.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "step 0000 : loss is 6242.35, accuracy on training set 3.12 %, accuracy on test set 21.59 %\n",
      "step 1000 : loss is 10386.96, accuracy on training set 90.62 %, accuracy on test set 82.59 %\n",
      "step 2000 : loss is 2835.85, accuracy on training set 90.62 %, accuracy on test set 86.03 %\n",
      "step 3000 : loss is 8463.08, accuracy on training set 87.50 %, accuracy on test set 82.85 %\n",
      "step 4000 : loss is 4352.61, accuracy on training set 87.50 %, accuracy on test set 86.25 %\n",
      "step 5000 : loss is 24092.93, accuracy on training set 87.50 %, accuracy on test set 88.73 %\n",
      "step 6000 : loss is 12096.09, accuracy on training set 90.62 %, accuracy on test set 89.41 %\n",
      "step 7000 : loss is 2649.42, accuracy on training set 93.75 %, accuracy on test set 91.07 %\n",
      "step 8000 : loss is 2693.52, accuracy on training set 96.88 %, accuracy on test set 88.62 %\n",
      "step 9000 : loss is 11871.29, accuracy on training set 90.62 %, accuracy on test set 87.93 %\n",
      "step 10000 : loss is 18648.36, accuracy on training set 84.38 %, accuracy on test set 87.40 %\n"
     ]
    }
   ],
   "source": [
    "image_width = mnist_image_width\n",
    "image_height = mnist_image_height\n",
    "image_depth = mnist_image_depth\n",
    "num_labels = mnist_num_labels\n",
    "\n",
    "#the dataset\n",
    "train_dataset = mnist_train_dataset\n",
    "train_labels = mnist_train_labels\n",
    "test_dataset = mnist_test_dataset\n",
    "test_labels = mnist_test_labels\n",
    "\n",
    "#number of iterations and learning rate\n",
    "num_steps = 10001\n",
    "display_step = 1000\n",
    "learning_rate = 0.5\n",
    "batch_size = 32\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    #1) First we put the input data in a tensorflow friendly form. \n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_width, image_height, image_depth))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, num_labels))\n",
    "    tf_test_dataset = tf.constant(test_dataset, tf.float32)\n",
    "  \n",
    "    #2) Then, the weight matrices and bias vectors are initialized\n",
    "    #as a default, tf.truncated_normal() is used for the weight matrix and tf.zeros() is used for the bias vector.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_width * image_height * image_depth, num_labels]), tf.float32)\n",
    "    bias = tf.Variable(tf.zeros([num_labels]), tf.float32)\n",
    "  \n",
    "    #3) define the model:\n",
    "    #A one layered fccd simply consists of a matrix multiplication\n",
    "    def model(data, weights, bias):\n",
    "        return tf.matmul(flatten_tf_array(data), weights) + bias\n",
    "\n",
    "    logits = model(tf_train_dataset, weights, bias)\n",
    "\n",
    "    #4) calculate the loss, which will be used in the optimization of the weights\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "\n",
    "    #5) Choose an optimizer. Many are available.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    #6) The predicted values for the images in the train dataset and test dataset are assigned to the variables train_prediction and test_prediction. \n",
    "    #It is only necessary if you want to know the accuracy by comparing it with the actual values. \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    test_prediction = tf.nn.softmax(model(tf_test_dataset, weights, bias))\n",
    "\n",
    "\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "#     writer = tf.summary.FileWriter(\"./graph3\", sess.graph)\n",
    "#     writer.close\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % display_step == 0):\n",
    "            train_accuracy = accuracy(predictions, batch_labels[:, :])\n",
    "            test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "            message = \"step {:04d} : loss is {:06.2f}, accuracy on training set {:02.2f} %, accuracy on test set {:02.2f} %\".format(step, l, train_accuracy, test_accuracy)\n",
    "            print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
